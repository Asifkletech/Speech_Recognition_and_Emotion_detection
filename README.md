
# ğŸ¤ Speech Emotion Recognition (SER) with LSTM

This project classifies emotions from speech using an **LSTM model** trained on datasets like **RAVDESS, TESS, SAVEE, and CREMA-D**.The model takes **MFCC features** extracted from audio files and predicts emotions.

---

## ğŸ“Œ Features
âœ… Supports multiple **speech emotion datasets**  
âœ… **Data augmentation** applied to improve performance  
âœ… Uses **MFCC features** for audio processing  
âœ… **LSTM-based deep learning model**  
âœ… Can test **any audio format (MP3, FLAC, WAV, etc.)**  
âœ… Automatically **converts audio** to WAV format before testing  

---

## ğŸš€ Installation
### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Asifkletech/Speech_Recognition_and_Emotion_detection.git
cd speech-emotion-recognition
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Dataset Used
- **RAVDESS**  
- **TESS**  
- **SAVEE**  
- **CREMA-D**  

### Total emotions classified:
ğŸ­ **Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise,Calm**

---

## ğŸ—ï¸ Model Architecture
- **Feature Extraction**: MFCC (Mel-Frequency Cepstral Coefficients)  
- **Deep Learning Model**: LSTM with Fully Connected Layers  
- **Loss Function**: Categorical Cross-Entropy  
- **Optimizer**: Adam  
- **Augmentation**: Noise addition, pitch shift, speed change  

---

## ğŸƒâ€â™‚ï¸ Training the Model
### 1ï¸âƒ£ Ensure datasets are placed in the correct directories:
```bash
/dataset/TESS
/dataset/SAVEE
/dataset/CREMA-D
/dataset/RAVDESS
```

### 2ï¸âƒ£ Run the training script
```bash
python train_model.py
```

### 3ï¸âƒ£ Model is saved in the models/ directory
```bash
models/speech_emotion_model.h5
```

---

## ğŸ§ Testing the Model
You can test the trained model on any audio file using:
```bash
python test_model.py path/to/audio.mp3
```

âœ” Supports **MP3, FLAC, WAV, OGG** formats  
âœ” Converts audio to **WAV** automatically  
âœ” Outputs predicted emotion  

### Example Output:
```bash
Converting path/to/audio.mp3 to WAV format...
Predicted Emotion: happy
```

---

## ğŸ“ Project Structure
```
Speech-Emotion-Recognition/
â”‚â”€â”€ dataset/               # (Optional) Store small samples of datasets if legal
â”‚â”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py  # Script for feature extraction and augmentation
â”‚   â”œâ”€â”€ train_model.py         # Script to train the model
â”‚   â”œâ”€â”€ test_model.py           # Script for testing/inferencing
â”‚â”€â”€ models/
â”‚   â”œâ”€â”€ speech_emotion_recognition_with_augmentation.h5  # Saved trained model
â”‚â”€â”€ notebooks/
â”‚â”€â”€ requirements.txt           # Required Python libraries
â”‚â”€â”€ app.py                     # Deployment script (Flask/FastAPI)
â”‚â”€â”€ README.md                  # Project documentation
â”‚â”€â”€ .gitignore                  # Ignore unnecessary files


---


### Dependencies:
- **TensorFlow** (for LSTM model)  
- **Librosa** (for audio feature extraction)  
- **Pandas, NumPy, Scikit-learn** (for data processing)  
- **Pydub** (for audio format conversion)  
- **Matplotlib & Seaborn** (for visualization)  

---

## ğŸ”¥ Future Enhancements
ğŸ”¹ Improve model accuracy with more data  
ğŸ”¹ Deploy as a web application using Flask or FastAPI  
ğŸ”¹ Implement real-time speech emotion detection  

---

## ğŸ¤ Contributing
Contributions are welcome!
1. Fork the repo
2. Create a new branch
3. Commit and push changes
4. Submit a pull request

---


